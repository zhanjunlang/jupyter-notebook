{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      " 0  1  2\n",
      " 3  4  5\n",
      "[torch.LongTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_data = np.arange(6).reshape((2,3))\n",
    "torch_data = torch.from_numpy(np_data)\n",
    "print(np_data)\n",
    "print(torch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "print(torch_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 1]\n",
      "\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [-1,-2,1,1]\n",
    "tensor = torch.Tensor(data)\n",
    "print(np.abs(data))\n",
    "print(np.abs(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1  0]\n",
      " [ 0 -1]]\n",
      "\n",
      "-1  0\n",
      " 0 -1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [[-1,-2],[1,1]]\n",
    "tensor = torch.Tensor(data)\n",
    "print(np.matmul(data,data))\n",
    "print(torch.mm(tensor,tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.FloatTensor([[1,2],[3,4]])\n",
    "var = Variable(tensor, requires_grad = True)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.5000  1.0000\n",
      " 1.5000  2.0000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v_out = torch.mean(var*var)\n",
    "v_out.backward()\n",
    "print(var.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 3.  4.]]\n"
     ]
    }
   ],
   "source": [
    "print(var.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将线性变成非线性y = AF(WX)<br>\n",
    "常见激励函数：relu sigmoid tanh<br>\n",
    "少量层：随便选<br>\n",
    "卷积：relu<br>\n",
    "循环：relu tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8VGX2+PHPSa+QkIReAtKLUkKz\niw3RlVV3FRXrIqKyq+6u67p8V3d13eZv7W1xRVdAQVQUFRtiWQslCRBKKKGHkk56m5nn98cMijGQ\nQO7k3pmc9+uVV6Zc7j0zOXN45rn3nivGGJRSSgWPELsDUEopZS0t7EopFWS0sCulVJDRwq6UUkFG\nC7tSSgUZLexKKRVktLArpVSQ0cKulFJBRgu7UkoFmTA7NpqcnGxSU1Pt2LRqAzIyMgqNMSl2bFtz\nW/lTc3PblsKemppKenq6HZtWbYCI7G7GMnOAS4B8Y8zQRp4X4AlgElAF3GiMyWxqvZrbyp+ak9ug\nUzGq7XoZmHiM5y8C+vl+pgPPtUJMSllCC7sKOB6PobrO3aJ1GGO+BIqPschk4BXjtQJIEJEuLdqo\nUq3ElqkYpVri31/u4K3MXF6/dTyJsRH+2kw3YO8R93N9jx1ouKCITMc7qqdnz57+ikcFoJp6N4UV\ntRRV1FFUWUthRR1FFXUUV9ZSXuOivNZFeY2Lipp6KmpdVNS4+OmIbvxu4sAWbVcLuwoo324v4pGP\nNnPRsC4kxIT7c1PSyGON9rg2xswGZgOkpaVpH+w2priyji0Hy8nJL2dvSTW5JVXsLfb+Lqmqb/Tf\nRIeH0i46jLjIMOKiwomPDKNjfBTxUWEM6Bzf4pi0sKuAkV9Wwy9fW0Pv5Fj+ccXJePdv+k0u0OOI\n+92B/f7coHK+kso6MveUkL67hKzcQ2w5WEFhRe13z0eEhdA9MZruiTEM696ebgnRpMRFkhQXQVJc\nJEmxESTFRRAT4d/Sq4VdBYR6t4eZr66hstbFq7eMJS7S76m7BJgpIguAsUCpMeZH0zAquFXXufl2\nRyHLN+fzzfYidhRUAhAWIgzu2o4JA1Po3ymeAZ3j6dcxno7xkYSE+HXA0Sxa2FVAeOSjLazaVcwT\nU4bTv1PLv6qKyGvA2UCyiOQCDwDhAMaY54GleA91zMF7uONNLd6oCgg19W4+3pTHO2v28VVOIbUu\nDzERoYzrk8QVI7uT1iuRU3okEBUeaneoR6WFXTnehxsOMvvLHVw3rheTh3ezZJ3GmKubeN4Ad1iy\nMRUQ1u49xGsr97B0/QHKa110aR/F1WN6MmFgR8b26UBkmHMLeUNa2JWj7Sys5J5F6zilRwL/d8kg\nu8NRQcbjMXy8KY8Xv9rB6l0lxESEctHQLlwxqhvjeic5YlrlRGhhV45VXefmtnkZhIYKz1wzIqBG\nTMrZjDF8tiWff364hc0Hy+meGM39lwzmytE9WmP/jd8F/itQQckYw/+9vYEteeW8dONouifG2B2S\nChKb9pfxwJINrN5VQq+kGJ6YMpyLh3UhLDR4ztfUwq4cacHqvbyZmcuvzu3H2QM62h2OCgKVtS4e\nX7aVOV/vIiE6nL/8dChXje5BeBAV9MO0sCvH2bCvlAeWbOSMfsnceW4/u8NRQSBjdzF3LlhLbkk1\nV4/pwb0TB5IQ47ezlm2nhV05SmlVPTPmZZAcG8ETU0YQGqA7r5QzuD2GZz/L4fFPt9E1IYpFM8Yz\nOrWD3WH5nRZ25Rgej+HXr68lr6yG128dTwf/9YFRbUBpVT13vJrJVzmFXHpKV/5y2VDaRfm1DYVj\naGFXjvHcF9v5dHM+f750CCN6JtodjgpgOwsr+cXLq9lbUsXfLx/GVaN7+LsFhaNoYVeO8M32Qv71\n8RZ+ckpXrh/fy+5wVABbvauYW15JR4B5vxjL2D5JdofU6iwr7CISCqQD+4wxl1i1XhX8DpbW8KvX\n1tAnJY6/Xz6sTY2slLW+2lbItFdW0zUhmpduHE2vpFi7Q7KFlSP2O4FsoJ2F61RBztvcK5OqOjcL\npo8kNghODlH2+DQ7j9vmZ9InOZZ508aSHBdpd0i2seQAThHpDlwM/MeK9am24x8fbCZ9dwl/v+Jk\n+nZseXMv1TYt35zHrXMzGNg5ngXTx7Xpog7WXRrvceB3gMei9ak2YOn6A/znq53cML4Xl57S1e5w\nVIBavauY2+ZlMqhLO+ZNGxvUx6c3V4sLu4gcvtJ7RhPLTReRdBFJLygoaOlmVYDbUVDB797IYniP\nBGZdPNjucFSAyj5Qxs0vr6ZbQjQv3zS6zRzO2BQrRuynAZeKyC5gATBBROY1XMgYM9sYk2aMSUtJ\nSbFgsypQVdW5uG1eJuGhwjPXjiQiLPhO6Vb+t/9QNdfPWUVsRBhzp40lqY1PvxypxZ8oY8x9xpju\nxphUYAqw3BgztcWRqaBkjOH/Fm9ga345T0wZQbeEaLtDUgGous7N9LnpVNe5eeUXYzSPGtChkmpV\nr67aw1tr9nHnuf04s79+c1PHzxjDbxetY+P+Mp66eoQlV9QKNpYeW2aM+Rz43Mp1quCRlXuIPy/Z\nxJn9U/jVBG3upU7MU8tzeH/9Ae67aCDnDNTOn43REbtqFYeq6rhtXiYp8ZE8ftXwgL0yjbLXV9sK\neWzZVn46vCvTz+xjdziOpWeDKL/zeAx3L1xLfnkNi2acqs291AnJL6vhroVr6JsSx1/1DOVj0hG7\n8rtnP8/hsy0F3H/JYIb3SLA7HBWA3B7DnQvWUlHr4plrRxIToWPSY9F3R/nV1zmFPPrJViYP78rU\ncdrcS52Yp5fn8O2OIh752cm6s7QZdMSu/OZAaTW/em0NJ6XE8Tf96qxOUFbuIZ5cvo2fDu/Kz9N6\n2B1OQNDCrvyizuXhjvmZ1NS7eW7qKP3qrE5ITb2buxeuJSUukj9PHmp3OAFDP23KL/72QTaZew7x\n9DUj6Nsxzu5wVID654db2F5QydxfjKF9tLYLaC4dsSvLvZe1n5e+3sWNp6Zyycna3EudmG+2FzLn\na2+TuDP66clsx0MLu7JUTn4F976RxcieCfxh0iC7w1EBqqLWxT2LsuiTHMvvL9I8Ol46FaMsU1Xn\n4vb5GUSGh2pzL9Uij32ylf2l1bwx41SiI0LtDifgaGFXljDG8Ie31rMtv4JXbh5Dl/balEmdmA37\nSnnp651cM6Yno3rpRc1PhA6plCXmrdzD22v3c/d5/XU+VJ0wt8cwa/F6OsRG8ruJA+0OJ2BpYVct\ntm7vIR56dxNnD0hh5jl97Q5HBbD5K3ezLreUP14ySI+CaQEt7KpFSirruH2+t7nXY1dqcy914vLK\nanjkwy2c3jdZL5XYQjrHrk6Yx2O4+/W1FJTXsmjGeBK1uZdqgYfe20St28NffjpUz1JuIR2xqxP2\n9Gc5fL6lgPt/MphTtLmXaoEvthbwXtYBZp7Tl9TkWLvDCXha2NUJ+XJrAY8t28plI7px7diedoej\nAlhNvZs/vr2BPimx3HqW9li3gk7FqOO2/1A1dy5YQ7+OcTx8mX5tVi3z1PJt7Cmu4rVbxhEZpses\nW0FH7Oq41Lk83D4/k3q3CejmXiIyUUS2iEiOiPy+kedvFJECEVnr+5lmR5zBblteObO/3MHlI7sx\n/qQku8MJGoH5qVS2+evSbNbuPcSz147kpJTAbO4lIqHAM8D5QC6wWkSWGGM2NVh0oTFmZqsH2EZ4\nPIZZizcQGxnGLG0/YSkdsatmW7JuPy9/s4ubT+vNpGFd7A6nJcYAOcaYHcaYOmABMNnmmNqcNzJy\nWbWrmPsuGkhSXKTd4QQVLeyqWXLyy/n9m1mM6pXIfZMC/ozAbsDeI+7n+h5r6AoRyRKRN0REr/Bg\noeLKOv76QTajUxP5+Sh9a62mhV01qbLWxYx5mUSHh/LMNSMJDw34tGlsb69pcP9dINUYczKwDPjv\nUVcmMl1E0kUkvaCgwMIwg9dfl2ZTUePi4cuG6UltfhDwn1DlX8YY7ntrPTsKKnjy6hF0bh9ld0hW\nyAWOHCZ2B/YfuYAxpsgYU+u7+wIw6mgrM8bMNsakGWPSUlK0T05TVuwo4o2MXG45s49ev9RPtLCr\nY5q7YjdL1u3n1+f357S+yXaHY5XVQD8R6S0iEcAUYMmRC4jIkTsRLgWyWzG+oFXrcjNr8Xp6dIjm\nVxP62R1O0NKjYtRRrdlTwkPvbWLCwI7cfnbwNPcyxrhEZCbwERAKzDHGbBSRB4F0Y8wS4Fcicing\nAoqBG20LOIjM/mIH2wsqeemm0dpn3Y+0sKtGFVfWccf8TDq1i+LRK08JunlQY8xSYGmDx+4/4vZ9\nwH2tHVcw21VYyVOf5XDxsC6cM6Cj3eEEtRZPxYhIDxH5TESyRWSjiNxpRWDKPm6P4c4FayisqOO5\na0eREKPNvVTLGGOY9fZ6IkNDuP8ng+0OJ+hZMcfuAn5jjBkEjAPuEBH9ywWwJz/dxv+2FfKnS4cw\nrHt7u8NRQWDxmn18nVPE7y4aSKd2QbED3tFaXNiNMQeMMZm+2+V4dzI1dkywCgCfb8nnyeXbuHxk\nN64eo8cXq5Yrrqzjofc2MbJnAteO0YZxrcHSo2JEJBUYAay0cr2qdew7VM1dC9cyoFM8D/90mDb3\nUpZ4+P1symtc/O3yk4NuX41TWVbYRSQOeBO4yxhT1sjzehKHg9W63Nw+PxOX2/DstSP1iAVlia9z\nCnkzM5dbz+rDgM56zHprsaSwi0g43qI+3xjzVmPL6Ekczvbw+9ms23uI//fzk+kToM29lLPU1HuP\nWU9NiuGXesx6q2rx4Y7i/b7+IpBtjHm05SGp1vbO2n288u1upp3em4lDA7q5l3KQx5ZtZVdRFfOn\njSUqXL8BtiYrRuynAdcBE47oXT3JgvWqVrAtr5zfv7me0amJ3HtRwDf3Ug6RsbuEF77cwdVjegTT\nGcsBo8UjdmPMVzTeVEk5XEWtixnzMoiNDOXp4GjupRygus7Nbxeto0v7aGZdrEc+20HPPG2jjDH8\n/s0sdhZWMm/aWD22WFnmnx9tZmdhJa/eMpa4SC0xdtAhWhv18je7eC/rAL+5YACnnqRflZU1Vuwo\n4qWvd3HD+F6aVzbSwt4GZewu4eH3szl3YEduO+sku8NRQaK0up7fLlpHalKM7q+xmX5PamOKKmqZ\n+WomXRKiePTK4XrCiLKEMYY/vLWeA6U1LJoxPmAvch4sdMTehnibe62lqNLb3Kt9TLjdIakgsWD1\nXt5ff4DfXNCfkT0T7Q6nzdPC3oY8sWwrX+UU8uClQxjaTZt7KWtszSvnz+9u5PS+ycw4U6f2nEAL\nexvx2ZZ8nlyew89Gdeeq0drcS1mjvKae2+ZlEBcZxqNXBV/f/kClE2FtQG5JFXcvXMvAzvE8NHmo\nNvdSlvB4DHcvXPfd2aUd4/WQWafQEXuQO9zcy+02PD91lDb3UpZ54tNtLMvO448XD2JcnyS7w1FH\n0BF7kHvovU1k5Zby/NRRpCbH2h2OChIfrD/AE59u42ejunPDqal2h6Ma0BF7EFu8Jpd5K/Yw/cw+\nTBza2e5wVJBYtbOYOxeuZWTPBP7yU53acyIt7EFqy8Fy7ntrPWNSO/C7CwfYHY4KElvzypn239V0\nT4zmxRtGa9dGh9LCHoS+P1IhnKevGUGYNvdSFsgtqeKGOauIDA/lvzeNITFWL3LuVPqJDzLGGO59\nM4tdRZU8dfUIOmpzL2WBvcVVTJm9gspaFy/fNJoeHWLsDkkdgxb2IDPn610sXX+Qey4cyPiT9EgF\n1XKHi3p5jYv508YxpKue3OZ0elRMEEnfVczflmZz3qBOzDirj93hqCCwNa+cG+esorLOzfxpY/WM\n5QChI/YgUVhRyx2vZtI1IZp/XXmKHqmgWuybnEKueO4bXB7Dq7doUQ8kOmIPAt7mXmsoqarnrdtG\n0z5am3uplnk9fS+zFq+nd3IsL900hm4J0XaHpI6DFvYg8NgnW/k6p4h/XnGyjqpUi9TUu3ngnY0s\nTN/L6X2TeXbqSNpF6UAh0GhhD3DLN+fx9Gc5XJnWnSu1uZdqgZz8cma+uoYteeXMPKcvd53XTw+V\nDVBa2APY3uIq7l64jsFd2vHg5KF2h6MCVJ3Lw7+/2M5Ty3OIiwrj5ZvGcFb/FLvDUi2ghT1A1dR7\nm3t5jOG5qSP1DEB1QlbuKOKBJRvZfLCcS07uwp8uHUJyXKTdYakW0sIeoP787ibW7ytl9nWj6JWk\nzb3U8dleUMHfP9jMJ5vy6NI+itnXjeKCIdpPKFhoYQ9Ab2bk8tqqPdx6Vh/9MKrjsnF/Kc9/sYP3\ns/YTExHGPRcO4ObTems75yCjhT3AbD5Yxqy31zO2dwfuuUCbe6mm1dS7+WRTHgtW7+HrnCLiIsO4\n5Yw+3HJmH512CVJa2ANIWU09t83LJD4qnKe0uZc6BrfHkLmnhPezDrB4zT5Kq+vplhDNPRcOYOq4\nXnquQ5DTwh4gjDH8blEWe4qreFUvQ6YaUVhRy6qdxSzfnM/yzfkUV9YRERrCBUM6cdXoHpx6UjKh\nek3SNsGSwi4iE4EngFDgP8aYv1uxXvW9F7/ayYcbD3LfRQMZq5cha/Nq6t1sy6tg04FS1uWWsmpn\nMTn5FQC0iwrjnIEdOX9wJ87qn0K8nmDU5rS4sItIKPAMcD6QC6wWkSXGmE0tXbfyWr2rmL99sJkL\nBndi+pna3MsKTQ1GRCQSeAUYBRQBVxljdrVmjC63h4KKWnYXVbG7qNL3u4rtBRXk5Ffg8hgA4iPD\nGJWayBUjuzO2TweGdWtPuE7TtWlWjNjHADnGmB0AIrIAmAwcd2GvqnNhjAURBZH88lrumJ9J98Ro\nHvm5NveyQjMHI78ASowxfUVkCvAP4KoT2Z4xhso6N+U19ZTXuCivqaesxkV5jYsK3/2SqnoKymsp\nqKglv6yGwopaiirrfvB5CAsRenSIoXdyLOcN6sTgru0Y0rUdPRJjCNEpFnUEKwp7N2DvEfdzgbEn\nsqLz/vUF+0trLAgpuMRGhPLyTWN0h5d1mjMYmQz8yXf7DeBpERFjjn/o8cXWAm58afUxlwkPFVLi\nIkmJj6R7YjQjeiaSEh9Jx/hIeiXFkJoUS5f2UbrDXDWLFYW9saHCj5JfRKYD0wF69uzZ6IrumNCX\nylqXBSEFjxARJg7tTPdEvWKNhZozGPluGWOMS0RKgSSgsOHKmsrtfp3i+cOkgcRHhRMXGUZ8VBjx\nUeG08/2OjwojJiJUv40py1hR2HOBI7tPdQf2N1zIGDMbmA2QlpbW6Kjn2rG9LAhHqSY1ZzDSrAEL\nNJ3b3RKimX7mSccbo1InzIrvdauBfiLSW0QigCnAEgvWq5S/NGcw8t0yIhIGtAeKWyU6pVqoxYXd\nGOMCZgIfAdnA68aYjS1dr1J+1JzByBLgBt/tnwHLT2R+XSk7iB25KiIFwO6jPJ1MI/OYNnBKHKCx\nNOZYcfQyxhyz76yITAIex3u44xxjzMMi8iCQboxZIiJRwFxgBN6R+pTDO1ubWO/Rctsp7xtoLI1x\nShzQwtwGmwr7sYhIujEmTeP4nsbi3Diay0nxaizOjQOsiUWPnVJKqSCjhV0ppYKMEwv7bLsD8HFK\nHKCxNMYpcTSXk+LVWH7MKXGABbE4bo5dKaVUyzhxxK6UUqoFtLArpVSQsb2wi8ifRGSfiKz1/Uw6\nynITRWSLiOSIyO/9EMcjIrJZRLJEZLGIJBxluV0ist4Xa7rFMRzzNYpIpIgs9D2/UkRSrdy+bxs9\nROQzEckWkY0icmcjy5wtIqVH/M3utzqOI7Z1zPdbvJ70vSdZIjLSX7EcD6fktW8btua2E/Lat522\nk9vGGFt/8HbQ+20Ty4QC24E+QASwDhhscRwXAGG+2/8A/nGU5XYByX54H5p8jcDtwPO+21OAhX6I\nowsw0nc7HtjaSBxnA++1Un4c8/0GJgEf4O3tMg5Y2RpxNSNuR+S1bzu25bZT8tq37jaT27aP2Jvp\nuzarxpg64HCbVcsYYz423vYIACvw9g9pTc15jZOB//puvwGcKxa3BDTGHDDGZPpul+NtE9HNym1Y\nbDLwivFaASSISBe7g2omv+c12J7bjshraFu57ZTCPtP3VWOOiCQ28nxjbVb9+Qe5Ge//lI0xwMci\nkiHedq1Wac5r/EErWeBwK1m/8H0lHgGsbOTp8SKyTkQ+EJEh/oqBpt/v1s6N4+G0vIbWz23H5TUE\nf263ysWsRWQZ0LmRp2YBzwEP4X2RDwH/wpt8P1hFI//2uI/TPFYcxph3fMvMAlzA/KOs5jRjzH4R\n6Qh8IiKbjTFfHm8sjYXXyGMn3Eq2pUQkDngTuMsYU9bg6Uy8PSsqfHPHbwP9/BEHTb/frfaeNOSU\nvG4qFptz21F5DW0jt1ulsBtjzmvOciLyAvBeI081q+d7S+MQkRuAS4BzjW+Sq5F17Pf9zheRxXi/\nalpR2I+nlWyu+LGVrIiE4038+caYtxo+f+SHwRizVESeFZFkY4zlTZSa8X5bkhsnGJsj8ro5sdiY\n247Ja2g7uW37VEyDOaPLgA2NLOb3nu/ivbjxvcClxpiqoywTKyLxh2/j3SnVWLwnwhGtZH1zmy8C\n2caYR4+yTOfDc6AiMgZvHhVZGYdv3c15v5cA1/uOIBgHlBpjDlgdy/FySl77YrEztx2R19DGcrs1\n9v42sWd4LrAeyPK9kC6+x7sCSxvsId6Kdw/7LD/EkYN3Pmut7+f5hnHg3bO/zvez0eo4GnuNwIN4\nP5AAUcAiX6yrgD5+eB9Ox/t1L+uI92ISMAOY4Vtmpu/1r8O7M+5UP+VGo+93g1gE74Wpt/vyKM3u\nnHZSXjsht52Q120tt7WlgFJKBRnbp2KUUkpZSwu7UkoFGS3sSikVZFrlcMeGkpOTTWpqqh2bVm1A\nRkZGoWnGdSH9QXNb+VNzc9uSwi4ic/AeI5tvjBna1PKpqamkp1vaP0up74jI0S6U7nea28qfmpvb\nVk3FvAxMtGhdSimlWsCSEbsx5kvxU6tN5Xx1Lg9VdS5qXR7q3R7cHoPLY7y/3QaXx/PdfbfHYAyY\nw2dGG++Bxea7u4ef9903viUbPB8iwjkDO7buC1XKzz7bks/Qru1JiY9s0XpabY7d1+RmOkDPnj1b\na7PqBFXVudhRUMmOwkr2FFVSUF5LYUUdBRW1FFfWUVnrorLWRVWdG5en9c+FiAoPYfNDF7X6dpXy\nl437S5kxN4OJQzvzxJQRLVpXqxV2Y8xsfBdpTUtL07OiHGb/oWr+t62AVTtLSN9dzO6iH5553i4q\njOT4SJLjIunfKY64yDBiIsKIiQj1/YQRGR5CeEgIoSFCWKgQdvh2iBAaKoSHhBAigIAgHG7MKoBI\nw/uHb3lvH17m8KMh1nd1Vco2pVX1zJiXQWJMBH+8ZHCL12fLUTHKGSprXbyZmcviNftYs+cQAB1i\nI0jrlcjPRnbnpI5x9EmJJTUplqjwUJujVSo4eTyGu19fy8HSGhbeOp7kuJZNw4AW9japotbF859v\n55Vvd1FW42Jwl3bcc+EALhjcib4d474bGSul/O/pz3JYvjmfhyYPYWTPxtr2Hz+rDnd8De8lpZJF\nJBd4wBjzohXrVtZ6Z+0+Hn4/m/zyWiYN68y0M/pYlkxKqePz+ZZ8Hlu2lctHdGPquF6Wrdeqo2Ku\ntmI9yn+q69zc/84GFmXkckr39jx/3Sgt6ErZaG9xFXcuWMuATvE8fNkwS78p61RMG5BfVsMNL61m\n88EyfjWhL3ee15/QEJ1uUcouNfVubpufgccY/n3dKKIjrN2HpYU9yO07VM01L6ygoLyWOTeO5pwB\neuy3UnZ74J2NbNhXxn+uT6NXUqzl69fCHsRKKuu4/sWVFFfWMX/aWEbo1ItStluwag8L0/fyywl9\nOW9wJ79sQwt7kKp3e7h1bgZ7S6qZe/MYLepKOUBW7iHuX7KRM/olc9d5/f22HW3bG6T++eFmVu0q\n5p9XnMzYPkl2h6NUm1dcWcdt8zJJiYvkySkj/LqfS0fsQeiLrQW88L+dXDeuFz8d0c3ucJRq89we\nw50L1lBQXssbt40nMTbCr9vTwh5kymvque/NLPp2jGPWxYPsDkcpBTy+bCv/21bI3y8fxsndE/y+\nPS3sQeZfH2/lQFkNb952qrYBUMoBPs3O46nlOVyZ1p0pY1qnAaLOsQeRbXnlzF2xm2vG9NSTj5Ry\ngF2Fldy1cC1Du7XjwclNXoPIMlrYg8hf3s8mJiKUX5/vv73tbZGIhIrIGhF5z+5YVOCornMzY14G\noSHCc9eOatVv0FrYg0TG7mK+2FrAzHP6kmRBdzj1A3cC2XYHoQKHMYZZi9ezJa+cx68aTo8OMa26\nfS3sQeKp5Tl0iI3guvHWNRJSICLdgYuB/9gdiwoc81bu4a01+7jr3P6cbcPZ3lrYg0BW7iE+31LA\nL07vTUyE7g+32OPA7wCP3YGowJC5p4QH393IOQNS+OWEvrbEoIU9CDy9PIf20eFcr6N1S4nIJUC+\nMSajieWmi0i6iKQXFBS0UnTKiQorarl9XiZd2kfz+FUjCLGp2Z4W9gC3s7CSjzflccOpqcRHhdsd\nTrA5DbhURHYBC4AJIjKv4ULGmNnGmDRjTFpKSkprx6gcwuX28MtX11BSVcdzU0fSPsa+z6MW9gA3\nf8VuwkKEqeP0AuFWM8bcZ4zpboxJBaYAy40xU20OSznUIx9v4dsdRTx82TCGdG1vayxa2ANYTb2b\nRRm5XDi0Mx3jo+wOR6k2672s/fz7ix1cO7YnPxvV3e5w9MzTQPbuuv2UVtdznYWX1FKNM8Z8Dnxu\ncxjKgTYfLOOeRVmM6pXIAz8ZYnc4gI7YA9q8lXvo1zGOsb072B2KUm1SaVU9t87NID4qjOeuHUlE\nmDNKqjOiUMdt0/4y1u09xLVje1p6rUSlVPO4PYY7F65h/6Fqnps6ko7tnDMdqoU9QL29dh9hIcLk\n4dqWVyk7PL5sK59vKeCBnwxhVC9nfWvWwh6A3B7DO2v3cfaAjn7v66yU+rEPNxzkqeU5XJXWg2vH\nOu+INC3sAejb7UXkldVymV5EQ6lWl5Nfzm9eX8spPRL48+QhjpwK1cIegBav2Ud8ZBjnDmr9HhRK\ntWVlNfVMn5tBdEQoz08d6djNJc0YAAARxklEQVRrHmhhDzDVdW4+3HCAScO6ODaplApGHo/h1wvX\nsaeoimeuGUmX9tF2h3RUWtgDzOdb8qmsczN5eFe7Q1GqTXlqeQ7LsvP4v4sHOf4C8VrYA8xHGw+S\nGBPOGD12XalW82l2Ho9/upXLR3TjhlNT7Q6nSVrYA0idy8Onm/M5d1AnwkL1T6dUa9hRUMFdC9Yy\nuEs7/nr5MEfuLG1Iq0MAWbGjiPIaFxcO6Wx3KEq1CeU13jNLw0KFf1/Xupe3awntFRNAPtp4kJiI\nUM7ol2x3KEoFPY/HcPfCteworGTuzWPonti6l7drCR2xBwiPx/DJpjzO6p8SMKMGpQLZo59sZVl2\nPvdfMphT+wbWYEoLe4BYs/cQ+eW1Og2jVCt4d91+nv4shymjewTklcm0sAeIjzcdJCxEOGegnpSk\nlD9t2FfKPW+sY3RqIg9OHhoQO0sb0sIeAIwxfLwxj/EnJdE+Wi9/p5S/FJTXcssr6XSIieC5qaMc\n04b3eAVm1G3MtvwKdhZW6jSMUn5U63IzY14GJVV1vHBDGslxkXaHdML0qJgA8NGGg4jABYM72R2K\nUkHJGMMf395Axu4SnrlmpO3XLG0pS0bsIjJRRLaISI6I/N6KdarvfbTpICN6JDiqkb9SweTlb3bx\nenouv5rQl4tP7mJ3OC3W4sIuIqHAM8BFwGDgahEZ3NL1Kq/ckio27CvTaRil/OSrbYX85f1sLhjc\nibvO6293OJawYsQ+BsgxxuwwxtQBC4DJFqxXAR9vzAPgAi3sSlkuJ7+c2+Zn0DcljkevGk5ISOAd\nAdMYKwp7N2DvEfdzfY/9gIhMF5F0EUkvKCiwYLNtw0cbD9K/Uxy9k2PtDkWpoFJUUcvNL6cTGRbC\nizemERcZPLscrSjsjf0XZ370gDGzjTFpxpi0lJQUCzYb/Ioqalm9q1inYZSyWE29m1vnZpBXVsML\n16cFVLuA5rDiv6hcoMcR97sD+y1Yb5v36eZ8PAYt7EpZyBjDvW9mke47AmZEz0S7Q7KcFSP21UA/\nEektIhHAFGCJBett8z7eeJBuCdEM6drO7lCUChpPfprDO2v3c8+FA4LiCJjGtLiwG2NcwEzgIyAb\neN0Ys7Gl623rKmtdfLmtkAuGdArIU5qVcqJ31u7jsWVbuWJkd24/+yS7w/EbS/YWGGOWAkutWJfy\n+mJrAXUuj07DKGWRjN3F3LMoi7G9O/C3ALlgxonSlgIO9cGGgyTFRpDWK/jm/wKFiPQQkc9EJFtE\nNorInXbHpE7MzsJKbnklg26J0TwfwD1gmiu4X12Aqql3szw7jwuG6CXwbOYCfmOMGQSMA+7Qk+8C\nT0F5LdfPWQnAnBtHkxgbYXNE/qdVw4G+2lZIZZ2biUODc8dOoDDGHDDGZPpul+Pdh/SjczSUc1XU\nurjp5VUUltcx58bRbeZ8EC3sDvTBhoO0iwpjfJ8ku0NRPiKSCowAVjbynJ5850D1bg+3zcsg+0A5\nz147kuE9EuwOqdVoYXeYOpeHTzYd5LzBnYJ+HjBQiEgc8CZwlzGmrOHzevKd8xw+Vv1/2wr52+XD\n2twFarRyOMy3O4ooq3ExSadhHEFEwvEW9fnGmLfsjkc1zz8/2sJbmfv4zfn9uTKtR9P/IMhoYXeY\nDzccIDYilNP7BdbFc4OReI+HexHINsY8anc8qnle+nonz32+nWvG9mTmhL52h2MLLewO4vZ4L4E3\nYVAnosJD7Q5HwWnAdcAEEVnr+5lkd1Dq6F5fvZc/v7uJiUM681CAXq/UCsHTziwIrNxRRFFlHRcN\n1ZOSnMAY8xWNN7lTDvTuuv3c+1YWZ/VP4YmrhxMaJC14T4SO2B1k8Zp9xEWGMaGN7ehRqqWWbcrj\n7oVrGZ3ageenjiIyrG1/49XC7hDVdW4+2HCQi4Z21mkYpY7D1zmF3P5qJkO6tuPFG9KIjtDPjxZ2\nh1iWnUdFrYvLRuj5L0o11+pdxUz7bzq9k2J5+aYxxEeF2x2SI2hhd4i31+yjS/soxulJSUo1y4od\nRdwwZxVdEqKYO21Mm2gV0Fxa2B2gqKKWL7YWcOnwrkFzzUWl/OnrnEJufGkV3RKiWTB9HB3jo+wO\nyVH0qBgHWLxmHy6P0WkYpZrhy60F3PJKOr2TY5k3bSzJcZF2h+Q4Wtht5vEY5q/cw6heiQzsrFdK\nUupYlm/OY8a8TE5KiWP+tLF00OmXRulUjM2+3l7IzsJKrhvXy+5QlHK0Rel7ueWVDAZ0iue1W7So\nH4uO2G02b8VuOsRGcNEwPSlJqcYYY3jui+3888MtnNEvmeemjiIuUkvXsei7Y6MDpdV8simPW886\nqc2fUKFUYzwew4PvbeLlb3YxeXhXHvnZKdr1tBm0sNvov9/sBuCaMT1tjkQp56muc/ObRWtZuv4g\nvzi9N7MmDdKjxppJC7tNSqvrmbdiN5OGdaFHhxi7w1HKUfYfquaWV9LZdKCMWZMGMe2M3m22odeJ\n0MJuk3krdlNR6+K2s0+yOxSlHCVjdwm3zs2gpt7NizekMWFgJ7tDCjha2G1QVlPPC//bwdkDUhjS\ntb3d4SjlCMYY5q3YzUPvZdMlIYrXbhlLv07xdocVkLSw22D2Fzs4VFXPby8YYHcoSjlCWU09v38z\ni6XrD3LOgBQevXK4tghoAS3srSyvrIYXv9rJT07pytBuOlpXat3eQ/zytTXsO1TNfRcN5JYz+uhO\n0hbSwt7KHnxvEx5juEdH66qNq3W5eWLZNv795Q46xUfy+q3jGdUr0e6wgoIW9lb0xdYC3s86wK/P\n70/PJD0SRrVd6/Ye4reL1rEtv4Ir07oz6+LBtI/WlrtW0cLeSg5V1XHvG1mclBLLrWf1sTscpWxR\nUlnHvz7Zwqsr99AxPoqXbhrNOQP0imFW08LeCowx/GHxeooqa/nPDafpWaaqzXG5Pby2ag//7+Ot\nVNS6uH58Knef319H6X6ihb0VPPv5dpauP8gfJg3UHaaqTXF7DO9l7efJT7exvaCS8X2SeODSwdrJ\n1M+0sPvZO2v38chHW5g8vCu3nKFTMKptcLk9fLDhIE9+uo1t+RX07xTH81NHceGQTnoGaSvQwu5H\n72cd4Nevr2NM7w7844qTNaFV0DtUVceC1XuZ++1u9h2qpl/HOJ6+ZgSThnbRQxhbkRZ2PzDG8OJX\nO3l4aTajeiYy58bRRIXrvLoKTm6P4ZvthSzO3MfSDQeoqfdw6klJ3P+TwZw3qBOhWtBbnRZ2ixVW\n1HLfW+v5ZFMeE4d05rGrhhMdoUVdBReX20P67hI+2ZTHu+v2k19eS3xUGJeP7M7143vpHLrNtLBb\npN7t4fX0vTz2yVbKql3MmjSIX5zeW79+qqBgjGF3URWrdhXz1bZCPt+ST1mNi4jQEM4akMLlI7px\nzsCO+s3UIbSwt1BpdT1vr9nHS1/vZFdRFaN6JfLwZUN1xKICWmlVPZsOlLHpQBlr9pSwamcx+eW1\nACTFRnDBkM6cN6gjp/dL0asZOVCL/iIi8nPgT8AgYIwxJt2KoJzMGENuSTXfbi9iWXYeX24roKbe\nw8nd2/tajHbUnaRBREQmAk8AocB/jDF/tzkky9S7Pew/VM2uoip2F1Wys7CS3UVVbDlYzr5D1d8t\n17ldFOP6JDGmdwfG9u7ASSlx+k3U4Vr6X+0G4HLg3xbE4hhuj6G0up7iyjoOlFaz25f42wsqWbf3\nEEWVdQB0aR/Fz0f14Mq0HgzrrsenBxsRCQWeAc4HcoHVIrLEGLPJ3sh+zOX2UF3vpqzGRWlVPaXV\n9ZTV+H5X13Ooqp788hryy2vJK6slv6zmuzw+LCYilF5JsYzslcjUcb0Y3LUdg7rE0zE+yqZXpU5U\niwq7MSYbsGyE+tqqPVTUuDAYjAGP4bvbxvh+g+85g/EG8YPlDt/m8DK+f3P4dq3LQ2292/vb5aam\n/vvflbUuSqrqOFRdjzE/jC0yLITUpFjOGdiR4T0SGNUrkYGd43V0HtzGADnGmB0AIrIAmAwcV2HP\nLaniww0HcXkMbo/B5Ta4PZ7v73/323PE898/Xu/2UOvyUFPvpqbeTXW9N1+rffdr6t3Uu80xYwgN\nEZLjIujULopuCVGM6JlAp/gouiREkZoUS2pyDClxkZrPQaLVJsdEZDowHaBnz8av8fnkp9s4UFpz\nnOsF8a6fEAHB+8Dh2yIQIuJbBiLDQ4kMCyEyLISo726HkhwXRs8OMXSIjSAxNoIOMeEkxkbQMT6K\n1OQYOsVH6dfPtqcbsPeI+7nA2IYLNZXbuwqr+Mv72T96PDxUCA0RwkJCfL/l+9+h3z8eKkJUeAiR\n4aEkxETQJTyUqPAQoiNCiQwLJToilKiwUKIjQmgXFU77aO9PO9/v9jHhxEWEaf62IU0WdhFZBnRu\n5KlZxph3mrshY8xsYDZAWlpao8OLj+8+8/A2f1CY5cjb+Aq1WPdNQamjaCzBfpS7TeX22D4dWP+n\nC35QwLXIKn9qsrAbY85rjUAA4qO0IZBylFygxxH3uwP7j3cl4aEhhIeGWBaUUk3RbFPq6FYD/USk\nt4hEAFOAJTbHpFSTWlTYReQyEckFxgPvi8hH1oSllP2MMS5gJvARkA28bozZaG9USjVNTMPDP1pj\noyIFwO6jPJ0MFLZiOEfjlDhAY2nMseLoZYxJac1gDjtGbjvlfQONpTFOiQMsyG1bCvuxiEi6MSZN\n4/iexuLcOJrLSfFqLM6NA6yJRefYlVIqyGhhV0qpIOPEwj7b7gB8nBIHaCyNcUoczeWkeDWWH3NK\nHGBBLI6bY1dKKdUyThyxK6WUagHbC7uI/ElE9onIWt/PpKMsN1FEtohIjoj83g9xPCIim0UkS0QW\ni0jCUZbbJSLrfbFa2qa4qdcoIpEistD3/EoRSbVy+75t9BCRz0QkW0Q2isidjSxztoiUHvE3u9/q\nOI7Y1jHfb/F60veeZInISH/Fcjyckte+bdia207Ia9922k5ue7sm2veDt5/7b5tYJhTYDvQBIoB1\nwGCL47gACPPd/gfwj6MstwtI9sP70ORrBG4HnvfdngIs9EMcXYCRvtvxwNZG4jgbeK+V8uOY7zcw\nCfgAb1+XccDK1oirGXE7Iq9927Ett52S1751t5nctn3E3kzftU81xtQBh9unWsYY87HxnmkIsAJv\nX5DW1JzXOBn4r+/2G8C5YnEnNGPMAWNMpu92Od4zLrtZuQ2LTQZeMV4rgAQR6WJ3UM3k97wG23Pb\nEXkNbSu3nVLYZ/q+aswRkcRGnm+sfao//yA34/2fsjEG+FhEMsTbrtUqzXmN3y3j+6CWAkkWxvAD\nvq/EI4CVjTw9XkTWicgHIjLEXzHQ9Pvd2rlxPJyW19D6ue24vIbgz+1W6ccux2j9CzwHPIT3RT4E\n/Atv8v1gFY382+M+nOdYcRhfC2IRmQW4gPlHWc1pxpj9ItIR+ERENhtjvjzeWBoLr5HHGr5GS96H\n5hCROOBN4C5jTFmDpzPxntpc4Zs7fhvo5484aPr9brX3pCGn5HVTsdic247Ka2gbud0qhd00s/Wv\niLwAvNfIU5a0T20qDhG5AbgEONf4JrkaWcd+3+98EVmM96umFYW9Oa/x8DK5IhIGtAeKLdj2D4hI\nON7En2+Meavh80d+GIwxS0XkWRFJNsZY3mujGe+3JblxgrE5Iq+bE4uNue2YvIa2k9u2T8U0mDO6\nDO91VBvye/tU8V60+F7gUmNM1VGWiRWR+MO38e6UaizeE9Gc17gEuMF3+2fA8qN9SE+Ub27zRSDb\nGPPoUZbpfHgOVETG4M2jIivj8K27Oe/3EuB63xEE44BSY8wBq2M5Xk7Ja18sdua2I/Ia2lhut8be\n3yb2DM8F1gNZvhfSxfd4V2Bpgz3EW/HuYZ/lhzhy8M5nrfX9PN8wDrx79tf5fjZaHUdjrxF4EO8H\nEiAKWOSLdRXQxw/vw+l4v+5lHfFeTAJmADN8y8z0vf51eHfGneqn3Gj0/W4Qi+C94PR2Xx6l2Z3T\nTsprJ+S2E/K6reW2nnmqlFJBxvapGKWUUtbSwq6UUkFGC7tSSgUZLexKKRVktLArpVSQ0cKulFJB\nRgu7UkoFGS3sSikVZP4/wq+NHa+xCyMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117e532e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(-5,5,200)\n",
    "x = Variable(x)\n",
    "x_np = x.data.numpy()\n",
    "\n",
    "y_relu = F.relu(x).data.numpy()\n",
    "y_sigmoid = F.sigmoid(x).data.numpy()\n",
    "y_tanh = F.tanh(x).data.numpy()\n",
    "y_softplus = F.softplus(x).data.numpy()\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(x_np,y_relu)\n",
    "plt.subplot(222)\n",
    "plt.plot(x_np,y_sigmoid)\n",
    "plt.subplot(223)\n",
    "plt.plot(x_np,y_tanh)\n",
    "plt.subplot(224)\n",
    "plt.plot(x_np,y_softplus)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4g0kIK7iEgD/X9XGvyvSHnDHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c91d8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#将一维变2维，torch只会处理2维以上的数据\n",
    "x = torch.unsqueeze(torch.linspace(-1,1,100),dim = 1)\n",
    "y = x.pow(2) + 0.2*torch.rand(x.size())\n",
    "x = Variable(x)\n",
    "y = Variable(y)\n",
    "plt.scatter(x.data.numpy(),y.data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Demo(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Demo,self).__init__()\n",
    "    \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden,n_output):\n",
    "        super(Net,self).__init__()\n",
    "        #隐藏层，参数：输入数据的维数和输出神经元的个数\n",
    "        self.hidden = torch.nn.Linear(n_feature,n_hidden)\n",
    "        #输出层，参数：输入为隐藏层的神经元个数和输出最后输出神经元的个数\n",
    "        self.predict = torch.nn.Linear(n_hidden,n_output)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.hidden(x))\n",
    "        #预测层在回归问题中一般不用激励函数，因为激励函数会把结果的取值\n",
    "        #限定在一个范围内\n",
    "        x = self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=1, out_features=10, bias=True)\n",
      "  (predict): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net =  Net(1,10,1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr学习效率\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.4209\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  8.6817\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  4.8917\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  3.9663\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(200): #训练步数\n",
    "    prediction = net(x)\n",
    "    \n",
    "    loss = loss_func(prediction,y)\n",
    "    if(t%50 == 0):\n",
    "        print(loss)\n",
    "    optimizer.zero_grad() #之前的梯度清零\n",
    "    loss.backward()       #反向传播求梯度\n",
    "    optimizer.step()      #梯度下降走一步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data = torch.ones(100,2)\n",
    "x0 = torch.normal(2*n_data,1)\n",
    "y0 = torch.zeros(100)\n",
    "x1 = torch.normal(-2*n_data,1)\n",
    "y1 = torch.ones(100)\n",
    "x = torch.cat((x0,x1),0).type(torch.FloatTensor)\n",
    "y = torch.cat((y0,y1),).type(torch.LongTensor)\n",
    "x,y = Variable(x),Variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net2(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden,n_output):\n",
    "        super(Net2,self).__init__()\n",
    "        #隐藏层，参数：输入数据的维数和输出神经元的个数\n",
    "        self.hidden = torch.nn.Linear(n_feature,n_hidden)\n",
    "        #输出层，参数：输入为隐藏层的神经元个数和输出最后输出神经元的个数\n",
    "        self.predict = torch.nn.Linear(n_hidden,n_output)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.hidden(x))\n",
    "        #预测层在回归问题中一般不用激励函数，因为激励函数会把结果的取值\n",
    "        #限定在一个范围内\n",
    "        x = F.softmax(self.predict(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = Net2(2,10,2) \n",
    "#输入为2维点，隐藏层有10个神经元，二分类问题用one-hot表示，所以输出为2维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr学习效率\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr=0.02)\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.6698\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5035\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.4170\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3808\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "for t in range(200): #训练步数\n",
    "    prediction = net2(x)\n",
    "    \n",
    "    loss = loss_func(prediction,y)\n",
    "    if(t%50 == 0):\n",
    "        print(loss)\n",
    "    optimizer.zero_grad() #之前的梯度清零\n",
    "    loss.backward()       #反向传播求梯度\n",
    "    optimizer.step()      #梯度下降走一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.7312  0.2688\n",
      " 0.8950  0.1050\n",
      " 0.8041  0.1959\n",
      " 0.9768  0.0232\n",
      " 0.9056  0.0944\n",
      " 0.9430  0.0570\n",
      " 0.9523  0.0477\n",
      " 0.9748  0.0252\n",
      " 0.9689  0.0311\n",
      " 0.9801  0.0199\n",
      " 0.9339  0.0661\n",
      " 0.9769  0.0231\n",
      " 0.9751  0.0249\n",
      " 0.9034  0.0966\n",
      " 0.9133  0.0867\n",
      " 0.9765  0.0235\n",
      " 0.9572  0.0428\n",
      " 0.9872  0.0128\n",
      " 0.9160  0.0840\n",
      " 0.9381  0.0619\n",
      " 0.9241  0.0759\n",
      " 0.9740  0.0260\n",
      " 0.9350  0.0650\n",
      " 0.9282  0.0718\n",
      " 0.9864  0.0136\n",
      " 0.9641  0.0359\n",
      " 0.9927  0.0073\n",
      " 0.9692  0.0308\n",
      " 0.7720  0.2280\n",
      " 0.9049  0.0951\n",
      " 0.8148  0.1852\n",
      " 0.9777  0.0223\n",
      " 0.9597  0.0403\n",
      " 0.9624  0.0376\n",
      " 0.8973  0.1027\n",
      " 0.8648  0.1352\n",
      " 0.9838  0.0162\n",
      " 0.9381  0.0619\n",
      " 0.7972  0.2028\n",
      " 0.9889  0.0111\n",
      " 0.9357  0.0643\n",
      " 0.8950  0.1050\n",
      " 0.8526  0.1474\n",
      " 0.9836  0.0164\n",
      " 0.8821  0.1179\n",
      " 0.9741  0.0259\n",
      " 0.9089  0.0911\n",
      " 0.9811  0.0189\n",
      " 0.8492  0.1508\n",
      " 0.9799  0.0201\n",
      " 0.9887  0.0113\n",
      " 0.8411  0.1589\n",
      " 0.6513  0.3487\n",
      " 0.9647  0.0353\n",
      " 0.8857  0.1143\n",
      " 0.7863  0.2137\n",
      " 0.9514  0.0486\n",
      " 0.9002  0.0998\n",
      " 0.9104  0.0896\n",
      " 0.9253  0.0747\n",
      " 0.8698  0.1302\n",
      " 0.8735  0.1265\n",
      " 0.9519  0.0481\n",
      " 0.9287  0.0713\n",
      " 0.9776  0.0224\n",
      " 0.9804  0.0196\n",
      " 0.9802  0.0198\n",
      " 0.9596  0.0404\n",
      " 0.9029  0.0971\n",
      " 0.9036  0.0964\n",
      " 0.9549  0.0451\n",
      " 0.9382  0.0618\n",
      " 0.9801  0.0199\n",
      " 0.9756  0.0244\n",
      " 0.9190  0.0810\n",
      " 0.9760  0.0240\n",
      " 0.9767  0.0233\n",
      " 0.9535  0.0465\n",
      " 0.9256  0.0744\n",
      " 0.8996  0.1004\n",
      " 0.9836  0.0164\n",
      " 0.9707  0.0293\n",
      " 0.9752  0.0248\n",
      " 0.7047  0.2953\n",
      " 0.9895  0.0105\n",
      " 0.8767  0.1233\n",
      " 0.9819  0.0181\n",
      " 0.9353  0.0647\n",
      " 0.8838  0.1162\n",
      " 0.8897  0.1103\n",
      " 0.9581  0.0419\n",
      " 0.9473  0.0527\n",
      " 0.7753  0.2247\n",
      " 0.8126  0.1874\n",
      " 0.7586  0.2414\n",
      " 0.9875  0.0125\n",
      " 0.9611  0.0389\n",
      " 0.9304  0.0696\n",
      " 0.9320  0.0680\n",
      " 0.9525  0.0475\n",
      " 0.0321  0.9679\n",
      " 0.0779  0.9221\n",
      " 0.0211  0.9789\n",
      " 0.0556  0.9444\n",
      " 0.1402  0.8598\n",
      " 0.1861  0.8139\n",
      " 0.4880  0.5120\n",
      " 0.0106  0.9894\n",
      " 0.0228  0.9772\n",
      " 0.0267  0.9733\n",
      " 0.0624  0.9376\n",
      " 0.1653  0.8347\n",
      " 0.0711  0.9289\n",
      " 0.0124  0.9876\n",
      " 0.0226  0.9774\n",
      " 0.0864  0.9136\n",
      " 0.0157  0.9843\n",
      " 0.1038  0.8962\n",
      " 0.0196  0.9804\n",
      " 0.0325  0.9675\n",
      " 0.1670  0.8330\n",
      " 0.0594  0.9406\n",
      " 0.0328  0.9672\n",
      " 0.1082  0.8918\n",
      " 0.0173  0.9827\n",
      " 0.1729  0.8271\n",
      " 0.0268  0.9732\n",
      " 0.1556  0.8444\n",
      " 0.1110  0.8890\n",
      " 0.1418  0.8582\n",
      " 0.0494  0.9506\n",
      " 0.1979  0.8021\n",
      " 0.0429  0.9571\n",
      " 0.0444  0.9556\n",
      " 0.0198  0.9802\n",
      " 0.0168  0.9832\n",
      " 0.0912  0.9088\n",
      " 0.0494  0.9506\n",
      " 0.0221  0.9779\n",
      " 0.0621  0.9379\n",
      " 0.3185  0.6815\n",
      " 0.0483  0.9517\n",
      " 0.0415  0.9585\n",
      " 0.0614  0.9386\n",
      " 0.0657  0.9343\n",
      " 0.0120  0.9880\n",
      " 0.1559  0.8441\n",
      " 0.0801  0.9199\n",
      " 0.0324  0.9676\n",
      " 0.0248  0.9752\n",
      " 0.0160  0.9840\n",
      " 0.0489  0.9511\n",
      " 0.0261  0.9739\n",
      " 0.0873  0.9127\n",
      " 0.0247  0.9753\n",
      " 0.0730  0.9270\n",
      " 0.0701  0.9299\n",
      " 0.6922  0.3078\n",
      " 0.0104  0.9896\n",
      " 0.0758  0.9242\n",
      " 0.0267  0.9733\n",
      " 0.0663  0.9337\n",
      " 0.0371  0.9629\n",
      " 0.0957  0.9043\n",
      " 0.0394  0.9606\n",
      " 0.0762  0.9238\n",
      " 0.1577  0.8423\n",
      " 0.0672  0.9328\n",
      " 0.0109  0.9891\n",
      " 0.0761  0.9239\n",
      " 0.0893  0.9107\n",
      " 0.1310  0.8690\n",
      " 0.1105  0.8895\n",
      " 0.0392  0.9608\n",
      " 0.0363  0.9637\n",
      " 0.0207  0.9793\n",
      " 0.0920  0.9080\n",
      " 0.0524  0.9476\n",
      " 0.1504  0.8496\n",
      " 0.0204  0.9796\n",
      " 0.1111  0.8889\n",
      " 0.0594  0.9406\n",
      " 0.0100  0.9900\n",
      " 0.0270  0.9730\n",
      " 0.2435  0.7565\n",
      " 0.0330  0.9670\n",
      " 0.1095  0.8905\n",
      " 0.0670  0.9330\n",
      " 0.1752  0.8248\n",
      " 0.3736  0.6264\n",
      " 0.3460  0.6540\n",
      " 0.0292  0.9708\n",
      " 0.0217  0.9783\n",
      " 0.0493  0.9507\n",
      " 0.0195  0.9805\n",
      " 0.0321  0.9679\n",
      " 0.0774  0.9226\n",
      " 0.0582  0.9418\n",
      " 0.0254  0.9746\n",
      " 0.0714  0.9286\n",
      "[torch.FloatTensor of size 200x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type Net2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net2,'net2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net2.state_dict(),'net2_param.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = torch.load('net2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.7320  0.2680\n",
      " 0.8957  0.1043\n",
      " 0.8050  0.1950\n",
      " 0.9770  0.0230\n",
      " 0.9062  0.0938\n",
      " 0.9435  0.0565\n",
      " 0.9527  0.0473\n",
      " 0.9751  0.0249\n",
      " 0.9692  0.0308\n",
      " 0.9804  0.0196\n",
      " 0.9345  0.0655\n",
      " 0.9771  0.0229\n",
      " 0.9754  0.0246\n",
      " 0.9040  0.0960\n",
      " 0.9139  0.0861\n",
      " 0.9768  0.0232\n",
      " 0.9576  0.0424\n",
      " 0.9874  0.0126\n",
      " 0.9166  0.0834\n",
      " 0.9386  0.0614\n",
      " 0.9245  0.0755\n",
      " 0.9742  0.0258\n",
      " 0.9355  0.0645\n",
      " 0.9287  0.0713\n",
      " 0.9866  0.0134\n",
      " 0.9645  0.0355\n",
      " 0.9929  0.0071\n",
      " 0.9695  0.0305\n",
      " 0.7728  0.2272\n",
      " 0.9056  0.0944\n",
      " 0.8157  0.1843\n",
      " 0.9779  0.0221\n",
      " 0.9601  0.0399\n",
      " 0.9628  0.0372\n",
      " 0.8979  0.1021\n",
      " 0.8656  0.1344\n",
      " 0.9840  0.0160\n",
      " 0.9386  0.0614\n",
      " 0.7980  0.2020\n",
      " 0.9891  0.0109\n",
      " 0.9361  0.0639\n",
      " 0.8957  0.1043\n",
      " 0.8534  0.1466\n",
      " 0.9838  0.0162\n",
      " 0.8828  0.1172\n",
      " 0.9743  0.0257\n",
      " 0.9095  0.0905\n",
      " 0.9813  0.0187\n",
      " 0.8500  0.1500\n",
      " 0.9801  0.0199\n",
      " 0.9888  0.0112\n",
      " 0.8419  0.1581\n",
      " 0.6520  0.3480\n",
      " 0.9651  0.0349\n",
      " 0.8864  0.1136\n",
      " 0.7871  0.2129\n",
      " 0.9518  0.0482\n",
      " 0.9008  0.0992\n",
      " 0.9110  0.0890\n",
      " 0.9258  0.0742\n",
      " 0.8705  0.1295\n",
      " 0.8743  0.1257\n",
      " 0.9523  0.0477\n",
      " 0.9292  0.0708\n",
      " 0.9778  0.0222\n",
      " 0.9806  0.0194\n",
      " 0.9805  0.0195\n",
      " 0.9600  0.0400\n",
      " 0.9035  0.0965\n",
      " 0.9043  0.0957\n",
      " 0.9553  0.0447\n",
      " 0.9387  0.0613\n",
      " 0.9804  0.0196\n",
      " 0.9758  0.0242\n",
      " 0.9196  0.0804\n",
      " 0.9763  0.0237\n",
      " 0.9770  0.0230\n",
      " 0.9539  0.0461\n",
      " 0.9261  0.0739\n",
      " 0.9003  0.0997\n",
      " 0.9838  0.0162\n",
      " 0.9710  0.0290\n",
      " 0.9755  0.0245\n",
      " 0.7055  0.2945\n",
      " 0.9897  0.0103\n",
      " 0.8774  0.1226\n",
      " 0.9821  0.0179\n",
      " 0.9359  0.0641\n",
      " 0.8844  0.1156\n",
      " 0.8904  0.1096\n",
      " 0.9585  0.0415\n",
      " 0.9478  0.0522\n",
      " 0.7761  0.2239\n",
      " 0.8133  0.1867\n",
      " 0.7595  0.2405\n",
      " 0.9877  0.0123\n",
      " 0.9615  0.0385\n",
      " 0.9309  0.0691\n",
      " 0.9325  0.0675\n",
      " 0.9529  0.0471\n",
      " 0.0318  0.9682\n",
      " 0.0774  0.9226\n",
      " 0.0209  0.9791\n",
      " 0.0552  0.9448\n",
      " 0.1395  0.8605\n",
      " 0.1856  0.8144\n",
      " 0.4880  0.5120\n",
      " 0.0105  0.9895\n",
      " 0.0226  0.9774\n",
      " 0.0264  0.9736\n",
      " 0.0620  0.9380\n",
      " 0.1648  0.8352\n",
      " 0.0707  0.9293\n",
      " 0.0123  0.9877\n",
      " 0.0224  0.9776\n",
      " 0.0859  0.9141\n",
      " 0.0155  0.9845\n",
      " 0.1033  0.8967\n",
      " 0.0194  0.9806\n",
      " 0.0322  0.9678\n",
      " 0.1665  0.8335\n",
      " 0.0590  0.9410\n",
      " 0.0325  0.9675\n",
      " 0.1076  0.8924\n",
      " 0.0172  0.9828\n",
      " 0.1721  0.8279\n",
      " 0.0265  0.9735\n",
      " 0.1546  0.8454\n",
      " 0.1105  0.8895\n",
      " 0.1413  0.8587\n",
      " 0.0490  0.9510\n",
      " 0.1971  0.8029\n",
      " 0.0425  0.9575\n",
      " 0.0441  0.9559\n",
      " 0.0196  0.9804\n",
      " 0.0166  0.9834\n",
      " 0.0908  0.9092\n",
      " 0.0490  0.9510\n",
      " 0.0218  0.9782\n",
      " 0.0617  0.9383\n",
      " 0.3181  0.6819\n",
      " 0.0479  0.9521\n",
      " 0.0411  0.9589\n",
      " 0.0610  0.9390\n",
      " 0.0653  0.9347\n",
      " 0.0118  0.9882\n",
      " 0.1554  0.8446\n",
      " 0.0796  0.9204\n",
      " 0.0321  0.9679\n",
      " 0.0246  0.9754\n",
      " 0.0158  0.9842\n",
      " 0.0485  0.9515\n",
      " 0.0259  0.9741\n",
      " 0.0868  0.9132\n",
      " 0.0244  0.9756\n",
      " 0.0726  0.9274\n",
      " 0.0697  0.9303\n",
      " 0.6928  0.3072\n",
      " 0.0103  0.9897\n",
      " 0.0754  0.9246\n",
      " 0.0264  0.9736\n",
      " 0.0659  0.9341\n",
      " 0.0368  0.9632\n",
      " 0.0952  0.9048\n",
      " 0.0391  0.9609\n",
      " 0.0757  0.9243\n",
      " 0.1568  0.8432\n",
      " 0.0668  0.9332\n",
      " 0.0107  0.9893\n",
      " 0.0756  0.9244\n",
      " 0.0888  0.9112\n",
      " 0.1305  0.8695\n",
      " 0.1098  0.8902\n",
      " 0.0389  0.9611\n",
      " 0.0359  0.9641\n",
      " 0.0205  0.9795\n",
      " 0.0915  0.9085\n",
      " 0.0520  0.9480\n",
      " 0.1498  0.8502\n",
      " 0.0202  0.9798\n",
      " 0.1106  0.8894\n",
      " 0.0590  0.9410\n",
      " 0.0098  0.9902\n",
      " 0.0267  0.9733\n",
      " 0.2430  0.7570\n",
      " 0.0327  0.9673\n",
      " 0.1090  0.8910\n",
      " 0.0666  0.9334\n",
      " 0.1745  0.8255\n",
      " 0.3730  0.6270\n",
      " 0.3454  0.6546\n",
      " 0.0290  0.9710\n",
      " 0.0214  0.9786\n",
      " 0.0490  0.9510\n",
      " 0.0193  0.9807\n",
      " 0.0318  0.9682\n",
      " 0.0769  0.9231\n",
      " 0.0578  0.9422\n",
      " 0.0252  0.9748\n",
      " 0.0709  0.9291\n",
      "[torch.FloatTensor of size 200x2]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "predict = net2(x)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = Net2(2,10,2)\n",
    "net2.load_state_dict(torch.load('net2_param.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.0000e+00\n",
      " 1.9140e-06\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "predict = net2(Variable(torch.FloatTensor([10,10])))\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 :\n",
      "[ 3.  6.  2.  9.  4.] | [ 8.  5.  9.  2.  7.]\n",
      "[  1.   7.  10.   8.   5.] | [ 10.   4.   1.   3.   6.]\n",
      "epoch 1 :\n",
      "[ 10.   7.   1.   3.   2.] | [  1.   4.  10.   8.   9.]\n",
      "[ 5.  9.  8.  4.  6.] | [ 6.  2.  3.  7.  5.]\n",
      "epoch 2 :\n",
      "[  6.  10.   1.   4.   2.] | [  5.   1.  10.   7.   9.]\n",
      "[ 8.  5.  3.  7.  9.] | [ 3.  6.  8.  4.  2.]\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as Data\n",
    "BATCH_SIZE = 5\n",
    "x = torch.linspace(1,10,10)\n",
    "y = torch.linspace(10,1,10)\n",
    "\n",
    "torch_dataset = Data.TensorDataset(data_tensor=x,target_tensor=y)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, #是否随机\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "for epoch in range(3):\n",
    "    print('epoch',epoch,':')\n",
    "    for step, (batch_x,batch_y) in enumerate(loader):\n",
    "        print(batch_x.numpy(),'|',batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "优化器<br>\n",
    "SGD<br>\n",
    "momentum(也是用SGD，不过加了momentum这个参数，视频中是设为0.8)<br>\n",
    "RMSprop<br>\n",
    "Adam<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision #包含一些数据库\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#超参数\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001\n",
    "DOWNLOAD_MNIST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    #改成tensor格式，和压缩到（0，1）\n",
    "    transform=torchvision.transforms.ToTensor(), \n",
    "    download=DOWNLOAD_MNIST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e6bbd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data.train_data.size())\n",
    "print(train_data.train_labels.size())\n",
    "plt.imshow(train_data.train_data[0].numpy(),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, #是否随机\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.MNIST(root='./mnist',train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = Variable(torch.unsqueeze(test_data.test_data,dim=1),\n",
    "                  volatile=True).type(torch.FloatTensor)[:2000]/255\n",
    "test_y = test_data.test_labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(test_x.size()) \n",
    "#unsqueeze加了BATCH_SIZE的维度,dim=1说明在第1维中插入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(test_data.test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(test_data.test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d( #(1，28，28)\n",
    "                in_channels=1,#输入图片的高度，彩色图片为3，黑白图片为1\n",
    "                out_channels=16, #输出高度，可以看成有16个filters叠在一起扫描\n",
    "                kernel_size=5, #过滤器维度\n",
    "                stride=1, #步长\n",
    "                padding=2 # if stride=1,padding=(kernel_size-1)/2\n",
    "            ), #->(16,28,28)\n",
    "            nn.ReLU(),#->(16,28,28)\n",
    "            nn.MaxPool2d(kernel_size=2), #可以想象成另一个filter\n",
    "            #->(16,14,14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,5,1,2), #->(32,14,14)\n",
    "            nn.ReLU(), # ->(32,14,14)\n",
    "            nn.MaxPool2d(2) #->(32,7,7)\n",
    "        )\n",
    "        self.out = nn.Linear(32*7*7,10) #输入要展平，输出因为有10类（10个数字）\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x) #(batch,32,7,7)\n",
    "        x = x.view(x.size(0),-1) #(batch,32*7*7)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.3019678592681885 | accuracy: 0.1305\n",
      "train loss: 0.4599365293979645 | accuracy: 0.8205\n",
      "train loss: 0.13245519995689392 | accuracy: 0.901\n",
      "train loss: 0.5097387433052063 | accuracy: 0.9125\n",
      "train loss: 0.1347232311964035 | accuracy: 0.936\n",
      "train loss: 0.1962229311466217 | accuracy: 0.947\n",
      "train loss: 0.09001033008098602 | accuracy: 0.9415\n",
      "train loss: 0.055662188678979874 | accuracy: 0.9565\n",
      "train loss: 0.22798699140548706 | accuracy: 0.952\n",
      "train loss: 0.128178209066391 | accuracy: 0.9635\n",
      "train loss: 0.18648329377174377 | accuracy: 0.9565\n",
      "train loss: 0.06422994285821915 | accuracy: 0.9635\n",
      "train loss: 0.1151735708117485 | accuracy: 0.9615\n",
      "train loss: 0.14468316733837128 | accuracy: 0.9635\n",
      "train loss: 0.03337810933589935 | accuracy: 0.968\n",
      "train loss: 0.057695526629686356 | accuracy: 0.975\n",
      "train loss: 0.05144820734858513 | accuracy: 0.9795\n",
      "train loss: 0.16215918958187103 | accuracy: 0.971\n",
      "train loss: 0.02815297059714794 | accuracy: 0.98\n",
      "train loss: 0.006536298897117376 | accuracy: 0.971\n",
      "train loss: 0.04456564784049988 | accuracy: 0.974\n",
      "train loss: 0.017808975651860237 | accuracy: 0.979\n",
      "train loss: 0.0966399684548378 | accuracy: 0.9725\n",
      "train loss: 0.047715045511722565 | accuracy: 0.9785\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(),lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        b_x = Variable(x)\n",
    "        b_y = Variable(y)\n",
    "        output = cnn(b_x)\n",
    "        loss = loss_func(output,b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step%50 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output,1)[1].data.squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / test_y.size(0)\n",
    "            print(\"train loss:\",loss.data[0],'|','accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output,1)[1].data.numpy()\n",
    "print(pred_y,'prediction number')\n",
    "print(test_y[:10].numpy(),'real number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是为什么使用(un)squeeze的理由"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50, 28, 28])\n",
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50, 28, 28])\n",
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50, 28, 28])\n",
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50, 28, 28])\n",
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50, 28, 28])\n",
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for step,(x,y) in enumerate(train_loader):\n",
    "    print(x.size())\n",
    "    print(x.squeeze().size())\n",
    "    if step == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.Tensor([[1,2,3,4,5],[6,7,8,9,10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "   5\n",
       "  10\n",
       " [torch.FloatTensor of size 2], \n",
       "  4\n",
       "  4\n",
       " [torch.LongTensor of size 2])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.Tensor([[1,2,3,4,5],[6,7,8,9,10]]),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.squeeze\n",
    "\n",
    "torch.squeeze(input, dim=None, out=None)\n",
    "将输入张量形状中的1 去除并返回。 如果输入是形如(A×1×B×1×C×1×D)，那么输出形状就为： (A×B×C×D)\n",
    "当给定dim时，那么挤压操作只在给定维度上。例如，输入形状为: (A×1×B), squeeze(input, 0) 将会保持张量不变，只有用 squeeze(input, 1)，形状会变成 (A×B)。\n",
    "\n",
    "注意： 返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。\n",
    "\n",
    "参数:\n",
    "\n",
    "input (Tensor) – 输入张量\n",
    "dim (int, optional) – 如果给定，则input只会在给定维度挤压\n",
    "out (Tensor, optional) – 输出张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.unsqueeze\n",
    "\n",
    "torch.unsqueeze(input, dim, out=None)\n",
    "返回一个新的张量，对输入的制定位置插入维度 1\n",
    "\n",
    "注意： 返回张量与输入张量共享内存，所以改变其中一个的内容会改变另一个。\n",
    "\n",
    "如果dim为负，则将会被转化dim+input.dim()+1\n",
    "参数:\n",
    "\n",
    "tensor (Tensor) – 输入张量\n",
    "dim (int) – 插入维度的索引\n",
    "out (Tensor, optional) – 结果张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 1\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28 #rnn time step/image height\n",
    "INPUT_SIZE = 28 #rnn input size/image width\n",
    "LR = 0.01\n",
    "DOWNLOAD_MNIST = False\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, #是否随机\n",
    "    num_workers=2,\n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist',\n",
    "                                       train=False,\n",
    "                                      transform=torchvision.transforms.ToTensor())\n",
    "test_x = Variable(test_data.test_data,\n",
    "                  volatile=True).type(torch.FloatTensor)[:2000]/255\n",
    "test_y = test_data.test_labels.numpy().squeeze()[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            batch_first=True, #(batch,time_step,input)\n",
    "        )\n",
    "        self.out = nn.Linear(64,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        r_out,(h_n,h_c) = self.rnn(x,None) \n",
    "        # x(batch,time_step,input_size)\n",
    "        # None是指没初始的hidden state\n",
    "        out = self.out(r_out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.3018622398376465 | accuracy: 0.116\n",
      "train loss: 0.781937301158905 | accuracy: 0.6\n",
      "train loss: 0.9549441337585449 | accuracy: 0.711\n",
      "train loss: 0.7302921414375305 | accuracy: 0.748\n",
      "train loss: 0.5319693088531494 | accuracy: 0.85\n",
      "train loss: 0.26437437534332275 | accuracy: 0.879\n",
      "train loss: 0.2926117777824402 | accuracy: 0.9125\n",
      "train loss: 0.22128325700759888 | accuracy: 0.912\n",
      "train loss: 0.14532454311847687 | accuracy: 0.913\n",
      "train loss: 0.17114056646823883 | accuracy: 0.9255\n",
      "train loss: 0.06482797116041183 | accuracy: 0.9315\n",
      "train loss: 0.30730584263801575 | accuracy: 0.931\n",
      "train loss: 0.1360687017440796 | accuracy: 0.951\n",
      "train loss: 0.18281289935112 | accuracy: 0.9275\n",
      "train loss: 0.26453647017478943 | accuracy: 0.9465\n",
      "train loss: 0.14338654279708862 | accuracy: 0.946\n",
      "train loss: 0.13650457561016083 | accuracy: 0.959\n",
      "train loss: 0.19890643656253815 | accuracy: 0.9525\n",
      "train loss: 0.30525192618370056 | accuracy: 0.957\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(),lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        b_x = Variable(x.squeeze())\n",
    "        b_y = Variable(y)\n",
    "        output = rnn(b_x)\n",
    "        loss = loss_func(output,b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step%50 == 0:\n",
    "            test_output = rnn(test_x)\n",
    "            pred_y = torch.max(test_output,1)[1].data.numpy().squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / test_y.size\n",
    "            print(\"train loss:\",loss.data[0],'|','accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIME_STEP =10\n",
    "LR = 0.02\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x,h_state):\n",
    "        r_out, h_state = self.rnn(x,h_state) #输入一个序列，h_state是最后一步的hidden state\n",
    "        outs = []\n",
    "        for time_step in range(r_out.size(1)):\n",
    "            outs.append(self.out(r_out[:,time_step,:]))\n",
    "            \n",
    "        return torch.stack(outs,dim=1),h_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.0000\n",
      "  0.3420\n",
      "  0.6428\n",
      "  0.8660\n",
      "  0.9848\n",
      "  0.9848\n",
      "  0.8660\n",
      "  0.6428\n",
      "  0.3420\n",
      " -0.0000\n",
      "[torch.FloatTensor of size 1x10x1]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -8.7423e-08\n",
      " -3.4202e-01\n",
      " -6.4279e-01\n",
      " -8.6603e-01\n",
      " -9.8481e-01\n",
      " -9.8481e-01\n",
      " -8.6603e-01\n",
      " -6.4279e-01\n",
      " -3.4202e-01\n",
      "  1.7485e-07\n",
      "[torch.FloatTensor of size 1x10x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(),lr = LR)\n",
    "loss_func = nn.MSELoss()\n",
    "h_state = None\n",
    "for step in range(2):\n",
    "    start,end=step*np.pi,(step+1)*np.pi\n",
    "    steps = np.linspace(start,end,TIME_STEP,dtype=np.float32)\n",
    "    x_np = np.sin(steps)\n",
    "    y_np = np.cos(steps)\n",
    "    \n",
    "    x = Variable(torch.from_numpy(x_np[np.newaxis,:,np.newaxis]))\n",
    "    print(x) #shape(batch,time_step,input_size)\n",
    "    y = Variable(torch.from_numpy(y_np[np.newaxis,:,np.newaxis]))\n",
    "    \n",
    "    prediction, h_state = rnn(x,h_state)\n",
    "    h_state = Variable(h_state.data)\n",
    "    \n",
    "    loss = loss_func(prediction,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print(loss.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28,128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64,12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12,3),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3,12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12,64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,28*28),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoder = eslf.decoder(encoded)\n",
    "        return encoded,decoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
