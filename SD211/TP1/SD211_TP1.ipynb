{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/javascript\" src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default\"></script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SD211 TP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.optimize import check_grad\n",
    "from scipy.sparse.linalg import svds\n",
    "import math\n",
    "from time import time\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_movielens(filename, minidata=False):\n",
    "    \"\"\"\n",
    "    Cette fonction lit le fichier filename de la base de donnees\n",
    "    Movielens, par exemple \n",
    "    filename = '~/datasets/ml-100k/u.data'\n",
    "    Elle retourne \n",
    "    R : une matrice utilisateur-item contenant les scores\n",
    "    mask : une matrice valant 1 si il y a un score et 0 sinon\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(filename, dtype=int)\n",
    "\n",
    "    R = sparse.coo_matrix((data[:, 2], (data[:, 0]-1, data[:, 1]-1)),\n",
    "                          dtype=float)\n",
    "    R = R.toarray()  # not optimized for big data\n",
    "\n",
    "    # code la fonction 1_K\n",
    "    mask = sparse.coo_matrix((np.ones(data[:, 2].shape),\n",
    "                              (data[:, 0]-1, data[:, 1]-1)), dtype=bool )\n",
    "    mask = mask.toarray()  # not optimized for big data\n",
    "\n",
    "    if minidata is True:\n",
    "        R = R[0:100, 0:200].copy()\n",
    "        mask = mask[0:100, 0:200].copy()\n",
    "\n",
    "    return R, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "rho=0.3\n",
    "R,mask=load_movielens(\"ml-100k/u.data\")\n",
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1\n",
    "'minidata' échantillonne les premières 100 rangs et les premières 200 colonnes des données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for i in range(mask.shape[0]):\n",
    "    for j in range(mask.shape[1]):\n",
    "        if mask[i][j]==True:\n",
    "            counter=counter+1\n",
    "print(counter) #counter=100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2\n",
    "Il y a 943 utilisateurs et 1682 films. Le nombre total de notes est 100000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3\n",
    "Si on pose |U|=1, |C|=1, R=10 et $\\rho=2$, la fonction objective devient $g(x, y) = \\frac{1}{2}(10-xy)^2 + (x^2+y^2)$<br>\n",
    "On calcule ensuite la matrice hessienne:\n",
    "$$\\nabla^2 f=\\begin{bmatrix}\n",
    " y^2+2& -10+2xy\\\\ \n",
    " -10+2xy& x^2+2\n",
    "\\end{bmatrix}$$\n",
    "Soit $h=(h_1,h_2)^T$ un vecteur non null.\n",
    "$$h^T\\nabla^2 fh=h_{1}^2(y^2+2)+h_{2}^2(x^2+2)+2h_{1}h_{2}(2xy-10)$$\n",
    "Si on prend $h_1=h_2=x=y=1$, $h^T\\nabla^2 fh=-10$, donc la matrice hessienne n'est pas positive, donc la fonction objective n'est pas convexe. \n",
    "Les deux gradients ne sont pas lipschitzien.\n",
    "Par le même exemple, \n",
    "$$g(x,y) = \\frac{1}{2}(10-xy)^2 + (x^2+y^2)$$\n",
    "on a:\n",
    "    $$\\frac{\\partial g}{\\partial x} = (y^2+2)x - 10y$$\n",
    "    $$\\frac{\\partial^2 g}{\\partial x^2} = y^2 + 2$$\n",
    "Quand $y \\rightarrow \\infty$, $\\frac{\\partial^2 g}{\\partial x^2}\\rightarrow \\infty$, donc $\\nabla_g(P)$ n'est pas lipschitzien. De la même façon, on peut conclure que $\\nabla_g(Q)$ n'est pas lipschitzien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "Le gradient de g est $-{Q^0}^T(1_K\\circ (R-Q^{0}P))+\\rho P$ <br>\n",
    "$\\nabla ^2 g={Q^0}^{T}Q^0+\\rho$ elle est définie positive car <br>\n",
    "$h^T(Q^TQ)h=(Qh)^TQH=\\left \\| QH \\right \\|^2\\geqslant 0$ et $\\rho>0$ <br>\n",
    "donc g est convexe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective(P, Q0, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme simplifie.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q0 : une matrice de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q0.dot(P)) *mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q0 ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = -Q0.T.dot(tmp)+rho*P\n",
    "\n",
    "    return val, grad_P\n",
    "\n",
    "def objective_Q(P0, Q, R, mask, rho):\n",
    "   \n",
    "\n",
    "    tmp = (R - Q.dot(P0)) *mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q ** 2) + np.sum(P0 ** 2))\n",
    "\n",
    "    grad_Q = -tmp.dot(P0.T)+rho*Q\n",
    "\n",
    "    return val, grad_Q\n",
    "\n",
    "def func(P):\n",
    "    P=P.reshape((4,1682))\n",
    "    tmp = (R - Q0.dot(P)) *mask\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q0 ** 2) + np.sum(P ** 2))\n",
    "    return val\n",
    "\n",
    "def grad(P):\n",
    "    P=P.reshape((4,1682))\n",
    "    tmp = (R - Q0.dot(P)) *mask\n",
    "    grad_P = -Q0.T.dot(tmp)+rho*P\n",
    "    grad_P=grad_P.reshape(-1)\n",
    "    return grad_P\n",
    "\n",
    "Q0,S,P0=svds(R,k=4,return_singular_vectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la différence de gradient est 1.156906\n",
      "ca fait 153.864886s\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "print(\"la différence de gradient est %f\" % check_grad(func,grad,P0.reshape(-1)))\n",
    "print(\"ca fait %fs\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(g, P0, gamma,epsilon):\n",
    "    P=P0\n",
    "    grad=g(P, Q0, R, mask, rho)[1]\n",
    "    iteration=0\n",
    "    while math.sqrt(np.sum(grad**2))>epsilon:\n",
    "        P=P-grad*gamma\n",
    "        val,grad=g(P, Q0, R, mask, rho)\n",
    "        iteration=iteration+1\n",
    "    return val,iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4\n",
    "On prend $\\frac{1}{L}$ comme le pas constant $\\gamma$ où L est la constante lipschitzienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la valeur minimale est: 369551.549915\n",
      "ca fait 0.617983s\n",
      "Il y a 26 itérations\n"
     ]
    }
   ],
   "source": [
    "L1=rho+math.sqrt(np.sum((Q0.T.dot(Q0))**2))\n",
    "gamma1=1/L1\n",
    "t0=time()\n",
    "val,iteration=gradient(objective,P0,gamma1,1)\n",
    "print(\"la valeur minimale est: %f\" % val)\n",
    "print(\"ca fait %fs\" % (time()-t0))\n",
    "print(\"Il y a %d itérations\" % iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1\n",
    "Nous utilisons Armijo's line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def armijo_line_search_P(g,P0,Q0,gamma0,epsilon):\n",
    "    beta=0.5\n",
    "    P=P0\n",
    "    val,grad=g(P, Q0, R, mask, rho)\n",
    "    sum_grad=np.sum(grad**2)\n",
    "    gamma=gamma0\n",
    "    iteration=0\n",
    "    while math.sqrt(sum_grad)>epsilon:\n",
    "        a=0.5\n",
    "        b=2*gamma\n",
    "        gamma=b\n",
    "        _val=g(P-gamma*grad, Q0, R, mask, rho)[0]\n",
    "        while _val>val-beta*gamma*sum_grad:\n",
    "            iteration=iteration+1\n",
    "            gamma=gamma*a\n",
    "            _val=g(P-gamma*grad, Q0, R, mask, rho)[0]\n",
    "        P=P-grad*gamma\n",
    "        val,grad=g(P, Q0, R, mask, rho)\n",
    "        sum_grad=np.sum(grad**2)\n",
    "        iteration=iteration+1\n",
    "    return val,iteration,P\n",
    "\n",
    "def armijo_line_search_Q(g,P0,Q0,gamma0,epsilon):\n",
    "    beta=0.5\n",
    "    Q=Q0\n",
    "    val,grad=g(P0, Q, R, mask, rho)\n",
    "    sum_grad=np.sum(grad**2)\n",
    "    gamma=gamma0\n",
    "    iteration=0\n",
    "    while math.sqrt(sum_grad)>epsilon:\n",
    "        a=0.5\n",
    "        b=2*gamma\n",
    "        gamma=b\n",
    "        _val=g(P0, Q-gamma*grad, R, mask, rho)[0]\n",
    "        while _val>val-beta*gamma*sum_grad:\n",
    "            iteration=iteration+1\n",
    "            gamma=gamma*a\n",
    "            _val=g(P0, Q-gamma*grad, R, mask, rho)[0]\n",
    "        Q=Q-gamma*grad\n",
    "        val,grad=g(P0, Q, R, mask, rho)\n",
    "        sum_grad=np.sum(grad**2)\n",
    "        iteration=iteration+1\n",
    "    return val,iteration,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la valeur minimale est: 369551.060504\n",
      "ca fait 0.374842s\n",
      "Il y a 13 itérations\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "print(\"la valeur minimale est: %f\" % armijo_line_search_P(objective,P0,Q0,0.5,1)[0])\n",
    "print(\"ca fait %fs\" % (time()-t0))\n",
    "print(\"Il y a %d itérations\" % armijo_line_search_P(objective,P0,Q0,0.5,1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 3.2\n",
    "Comme déjà calculé, $\\nabla ^2 g={Q^0}^{T}Q^0+\\rho$  est symétrique et définie positive, on peut utiliser la méthode des gradients conjugués"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_S(g,s):\n",
    "    return (g(s+0.0001*s)-g(s))/0.0001\n",
    "def armijo_line_search_S(g,s0,gamma0,epsilon):\n",
    "    beta=0.5\n",
    "    s=s0\n",
    "    grad=grad_S(g,s)\n",
    "    #print(grad)\n",
    "    val=g(s)\n",
    "    sum_grad=grad**2\n",
    "    gamma=gamma0\n",
    "    iteration=0\n",
    "    while math.sqrt(sum_grad)>epsilon:\n",
    "        a=0.5\n",
    "        b=2*gamma\n",
    "        gamma=b\n",
    "        _val=g(s-gamma*grad)\n",
    "        while _val>val-beta*gamma*sum_grad:\n",
    "            iteration=iteration+1\n",
    "            gamma=gamma*a\n",
    "            _val=g(s-gamma*grad)\n",
    "        s=s-grad*gamma\n",
    "        val=g(s)\n",
    "        grad=grad_S(g,s)\n",
    "        sum_grad=grad**2\n",
    "        #print(grad)\n",
    "        iteration=iteration+1\n",
    "    return val,iteration,s\n",
    "\n",
    "def conjugue(g,P0,Q0,epsilon):\n",
    "    P=P0\n",
    "    grad=g(P,Q0,R,mask,rho)[1]\n",
    "    d=-grad\n",
    "    iteration=0\n",
    "    #s=-1/(rho+math.sqrt(np.sum((Q0.T.dot(Q0))**2)))\n",
    "    while(math.sqrt(np.sum(grad**2))>epsilon):\n",
    "        f=lambda s:g(P+s*d,Q0,R,mask,rho)[0]\n",
    "        #s=optimize.fmin(f,0.5)[0]\n",
    "        s=armijo_line_search_S(f,1,0.5,100)[2]\n",
    "        _P=P+s*d\n",
    "        _grad=g(_P,Q0,R,mask,rho)[1]\n",
    "        b=np.sum(_grad**2)/np.sum(grad**2)\n",
    "        d=-_grad+b*d\n",
    "        P=_P\n",
    "        grad=_grad\n",
    "        iteration=iteration+1\n",
    "        #print(np.sum(grad**2))\n",
    "    return g(P,Q0,R,mask,rho)[0],iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la valeur minimale est: 369550.940809\n",
      "ca fait 3.253746s\n",
      "Il y a 7 itérations\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "val,iteration=conjugue(objective,P0,Q0,1)\n",
    "print(\"la valeur minimale est: %f\" % val)\n",
    "print(\"ca fait %fs\" % (time()-t0))\n",
    "print(\"Il y a %d itérations\" % iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.3\n",
    "<table>\n",
    "<tr>\n",
    "    <th></th>\n",
    "    <th>gradient</th>\n",
    "    <th>recherche linéaire</th>\n",
    "    <th>conjugué</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>résultat</td>\n",
    "    <td>369551</td>\n",
    "    <td>369551</td>\n",
    "    <td>369550</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>temps</td>\n",
    "    <td>0.617983s</td>\n",
    "    <td>0.374842s</td>\n",
    "    <td>3.253746s</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>itération</td>\n",
    "    <td>26</td>\n",
    "    <td>13</td>\n",
    "    <td>7</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "On constate que les valeurs minimales obtenues sont presque les mêmes. Le méthode de recherche linéaire prend le moins de temps. Le méthode des gradients conjugués a le moins de nombre itérations, mais prend le plus de temps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_objective(P, Q, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme complet.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q : la variable matricielle de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    grad_Q : le gradient par rapport a Q\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = -Q.T.dot(tmp)+rho*P\n",
    "\n",
    "    grad_Q = -tmp.dot(P.T)+rho*Q\n",
    "\n",
    "    return val, grad_P, grad_Q\n",
    "\n",
    "\n",
    "def total_objective_vectorized(PQvec, R, mask, rho):\n",
    "    \"\"\"\n",
    "    Vectorisation de la fonction precedente de maniere a ne pas\n",
    "    recoder la fonction gradient\n",
    "    \"\"\"\n",
    "\n",
    "    # reconstruction de P et Q\n",
    "    \n",
    "    n_items = R.shape[1]\n",
    "    n_users = R.shape[0]\n",
    "    F = PQvec.shape[0] / (n_items + n_users)\n",
    "    F=int(F)\n",
    "    Pvec = PQvec[0:n_items*F]\n",
    "    Qvec = PQvec[n_items*F:]\n",
    "    P = np.reshape(Pvec, (F, n_items))\n",
    "    Q = np.reshape(Qvec, (n_users, F))\n",
    "    \n",
    "    val, grad_P, grad_Q = total_objective(P, Q, R, mask, rho)\n",
    "    return val, np.concatenate([grad_P.ravel(), grad_Q.ravel()])\n",
    "\n",
    "def armijo_line_search_total(g,PQ0,gamma0,epsilon):\n",
    "    beta=0.5\n",
    "    PQ=PQ0\n",
    "    val,grad=g(PQ,R,mask,rho)\n",
    "    gamma=gamma0\n",
    "    iteration=0\n",
    "    sum_grad=np.sum(grad**2)\n",
    "    while math.sqrt(sum_grad)>epsilon:\n",
    "        a=0.5\n",
    "        b=2*gamma\n",
    "        gamma=b\n",
    "        _val=g(PQ-gamma*grad,R, mask, rho)[0]\n",
    "        while _val>val-gamma*beta*sum_grad:\n",
    "            iteration=iteration+1\n",
    "            gamma=gamma*a\n",
    "            _val=g(PQ-gamma*grad,R, mask, rho)[0]\n",
    "        PQ=PQ-gamma*grad\n",
    "        val,grad=g(PQ,R,mask,rho)\n",
    "        sum_grad=np.sum(grad**2)\n",
    "        iteration=iteration+1\n",
    "    return val,iteration,PQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la valeur minimale est: 36035.485912\n",
      "ca fait 10.721682s\n",
      "Il y a 280 itérations\n"
     ]
    }
   ],
   "source": [
    "PQ=np.concatenate([P0.ravel(), Q0.ravel()])\n",
    "t0=time()\n",
    "val,iteration,PQ=armijo_line_search_total(total_objective_vectorized,PQ,0.1,100)\n",
    "print(\"la valeur minimale est: %f\" % val)\n",
    "print(\"ca fait %fs\" % (time()-t0))\n",
    "print(\"Il y a %d itérations\" % iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la fonction objective n'est pas convexe, la valeur obtenue est un minimum local mais pas un minimum global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand on fixe P ou Q, la fonction objective est convexe et donc sa valeur diminue après chaque itération.Et puis, comme la fonction objective est positive donc elle est bornée. Donc cette méthode converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moindres_carres_alternes(P0,Q0):\n",
    "    P=P0\n",
    "    Q=Q0\n",
    "    iteration=0\n",
    "    while True:\n",
    "        L1=rho+math.sqrt(np.sum((Q.T.dot(Q))**2))  \n",
    "        gamma1=1/L1\n",
    "        _P=armijo_line_search_P(objective,P,Q,gamma1,100)[2]\n",
    "        L2=rho+math.sqrt(np.sum((P.dot(P.T))**2))\n",
    "        gamma2=1/L2\n",
    "        _Q=armijo_line_search_Q(objective_Q,_P,Q,gamma2,100)[2]\n",
    "        iteration=iteration+1\n",
    "        diff=total_objective(P, Q, R, mask, rho)[0]-total_objective(_P, _Q, R, mask, rho)[0]\n",
    "        diff=abs(diff)\n",
    "        if (diff/total_objective(P, Q, R, mask, rho)[0]<0.01):\n",
    "            break\n",
    "        else:\n",
    "            P=_P\n",
    "            Q=_Q\n",
    "        #print(total_objective(P, Q, R, mask, rho)[0])\n",
    "    return total_objective(_P, _Q, R, mask, rho)[0],_P,_Q,iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349.5847442150116\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "val,P,Q,iteration=moindres_carres_alternes(P0,Q0)\n",
    "print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la valeur minimale est: 57896.225177\n",
      "ca fait 349.584744s\n"
     ]
    }
   ],
   "source": [
    "print(\"la valeur minimale est: %f\" % val)\n",
    "print(\"ca fait %fs\" % 349.5847442150116)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 4.4 \n",
    "Les résultats obtenus par ces deux méthodes ne sont pas la solution optimale mais des minimums locals. Leurs P, Q, $\\hat{R}$ obtenus ne sont pas le même. La méthode des moindres carrés alternés prend beaucoup plus de temps.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th></th>\n",
    "    <th>gradient avec recherche linéaire</th>\n",
    "    <th>moindres carrés alternés</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>résultat</td>\n",
    "    <td>36035.485912</td>\n",
    "    <td>57896.225177</td>\n",
    "<tr>\n",
    "<tr>\n",
    "    <td>temps</td>\n",
    "    <td>10.721682s</td>\n",
    "    <td>349.584744s</td>\n",
    "<tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.5 \n",
    "Comme la méthode du gradient avec recherche linéaire a une meilleur performance, on utilise son résultat. Et puis, on recommande des films que l'utilisateur n'a pas vus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PQ=np.concatenate([P0.ravel(), Q0.ravel()])\n",
    "val,iteration,PQ=armijo_line_search_total(total_objective_vectorized,PQ,0.1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dix premiers films recommandés: \n",
      "1: movie 49, score 4.646734\n",
      "2: movie 63, score 4.600738\n",
      "3: movie 173, score 4.532604\n",
      "4: movie 21, score 4.432318\n",
      "5: movie 95, score 4.431730\n",
      "6: movie 180, score 4.426008\n",
      "7: movie 171, score 4.396582\n",
      "8: movie 11, score 4.383966\n",
      "9: movie 317, score 4.355034\n",
      "10: movie 172, score 4.303764\n"
     ]
    }
   ],
   "source": [
    "n_items = R.shape[1]\n",
    "n_users = R.shape[0]\n",
    "F = PQ.shape[0] / (n_items + n_users)\n",
    "F=int(F)\n",
    "Pvec = PQ[0:n_items*F]\n",
    "Qvec = PQ[n_items*F:]\n",
    "P = np.reshape(Pvec, (F, n_items))\n",
    "Q = np.reshape(Qvec, (n_users, F))\n",
    "_R=Q.dot(P)\n",
    "score = _R[300, :].ravel()\n",
    "_mask=mask[300, :].ravel()\n",
    "rank = (-score).argsort()\n",
    "print(\"dix premiers films recommandés: \")\n",
    "counter=0\n",
    "i=0\n",
    "while True:\n",
    "    if(_mask[rank[i]]!=0):\n",
    "        counter=counter+1\n",
    "        print(\"%d: movie %d, score %f\" % (counter, rank[i], score[rank[i]]))\n",
    "        if(counter==10):\n",
    "            break\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
